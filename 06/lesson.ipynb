{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワーク\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(nnet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "even.n <- 2 * (1:75)\n",
    "iris.train <- iris[even.n, ]\n",
    "iris.test <- iris[-even.n, ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## やってみよう\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  27\n",
      "initial  value 87.971684 \n",
      "iter  10 value 42.906863\n",
      "iter  20 value 21.385293\n",
      "iter  30 value 17.770811\n",
      "iter  40 value 17.736152\n",
      "iter  50 value 17.732462\n",
      "final  value 17.732462 \n",
      "converged\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            iris.nnetp\n",
       "             setosa versicolor virginica\n",
       "  setosa         25          0         0\n",
       "  versicolor      0         23         2\n",
       "  virginica       0          0        25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris.nnet = nnet(Species ~ ., size = 3, decay = 0.1, data = iris.train)\n",
    "iris.nnetp = predict(iris.nnet, iris.test[, -5], type = \"class\")\n",
    "table(iris.test[, 5], iris.nnetp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 75 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>setosa</th><th scope=col>versicolor</th><th scope=col>virginica</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.97909070</td><td>0.01990905</td><td>0.0010002462</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.97650269</td><td>0.02238917</td><td>0.0011081386</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.97957425</td><td>0.01944512</td><td>0.0009806315</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0.97564607</td><td>0.02321161</td><td>0.0011423237</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>0.96647924</td><td>0.03202518</td><td>0.0014955750</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>0.98009040</td><td>0.01895226</td><td>0.0009573385</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>0.97296328</td><td>0.02579134</td><td>0.0012453770</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>0.98374886</td><td>0.01544954</td><td>0.0008015995</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>0.98210521</td><td>0.01702091</td><td>0.0008738800</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>0.97862301</td><td>0.02036198</td><td>0.0010150123</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0.97361171</td><td>0.02517580</td><td>0.0012124954</td></tr>\n",
       "\t<tr><th scope=row>23</th><td>0.98231725</td><td>0.01681571</td><td>0.0008670413</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>0.96052423</td><td>0.03778454</td><td>0.0016912305</td></tr>\n",
       "\t<tr><th scope=row>27</th><td>0.97167077</td><td>0.02703694</td><td>0.0012922870</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>0.97856430</td><td>0.02041426</td><td>0.0010214362</td></tr>\n",
       "\t<tr><th scope=row>31</th><td>0.96667067</td><td>0.03184997</td><td>0.0014793581</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>0.98214845</td><td>0.01698049</td><td>0.0008710631</td></tr>\n",
       "\t<tr><th scope=row>35</th><td>0.97116502</td><td>0.02752235</td><td>0.0013126356</td></tr>\n",
       "\t<tr><th scope=row>37</th><td>0.98107477</td><td>0.01800806</td><td>0.0009171654</td></tr>\n",
       "\t<tr><th scope=row>39</th><td>0.97219957</td><td>0.02652021</td><td>0.0012802259</td></tr>\n",
       "\t<tr><th scope=row>41</th><td>0.97953851</td><td>0.01947836</td><td>0.0009831349</td></tr>\n",
       "\t<tr><th scope=row>43</th><td>0.97521951</td><td>0.02361926</td><td>0.0011612267</td></tr>\n",
       "\t<tr><th scope=row>45</th><td>0.97043161</td><td>0.02823553</td><td>0.0013328648</td></tr>\n",
       "\t<tr><th scope=row>47</th><td>0.97883376</td><td>0.02015707</td><td>0.0010091689</td></tr>\n",
       "\t<tr><th scope=row>49</th><td>0.97985446</td><td>0.01917815</td><td>0.0009673904</td></tr>\n",
       "\t<tr><th scope=row>51</th><td>0.01553383</td><td>0.96126489</td><td>0.0232012872</td></tr>\n",
       "\t<tr><th scope=row>53</th><td>0.01607439</td><td>0.92726892</td><td>0.0566566899</td></tr>\n",
       "\t<tr><th scope=row>55</th><td>0.01810790</td><td>0.89310649</td><td>0.0887856130</td></tr>\n",
       "\t<tr><th scope=row>57</th><td>0.01937892</td><td>0.89090739</td><td>0.0897136898</td></tr>\n",
       "\t<tr><th scope=row>59</th><td>0.01578612</td><td>0.94965555</td><td>0.0345583345</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>91</th><td>0.020818416</td><td>0.77531236</td><td>0.20386923</td></tr>\n",
       "\t<tr><th scope=row>93</th><td>0.019386628</td><td>0.94739809</td><td>0.03321528</td></tr>\n",
       "\t<tr><th scope=row>95</th><td>0.020764847</td><td>0.88841335</td><td>0.09082180</td></tr>\n",
       "\t<tr><th scope=row>97</th><td>0.020076931</td><td>0.92997039</td><td>0.04995268</td></tr>\n",
       "\t<tr><th scope=row>99</th><td>0.059335976</td><td>0.92328504</td><td>0.01737899</td></tr>\n",
       "\t<tr><th scope=row>101</th><td>0.002785882</td><td>0.03577229</td><td>0.96144183</td></tr>\n",
       "\t<tr><th scope=row>103</th><td>0.003768930</td><td>0.05405064</td><td>0.94218043</td></tr>\n",
       "\t<tr><th scope=row>105</th><td>0.003079249</td><td>0.04064080</td><td>0.95627995</td></tr>\n",
       "\t<tr><th scope=row>107</th><td>0.004807830</td><td>0.06565437</td><td>0.92953780</td></tr>\n",
       "\t<tr><th scope=row>109</th><td>0.003365508</td><td>0.04663381</td><td>0.95000068</td></tr>\n",
       "\t<tr><th scope=row>111</th><td>0.011017522</td><td>0.22739646</td><td>0.76158601</td></tr>\n",
       "\t<tr><th scope=row>113</th><td>0.004810508</td><td>0.07360760</td><td>0.92158189</td></tr>\n",
       "\t<tr><th scope=row>115</th><td>0.003107860</td><td>0.03948636</td><td>0.95740578</td></tr>\n",
       "\t<tr><th scope=row>117</th><td>0.005803757</td><td>0.09603333</td><td>0.89816291</td></tr>\n",
       "\t<tr><th scope=row>119</th><td>0.002646899</td><td>0.03455211</td><td>0.96280099</td></tr>\n",
       "\t<tr><th scope=row>121</th><td>0.003821692</td><td>0.05378072</td><td>0.94239759</td></tr>\n",
       "\t<tr><th scope=row>123</th><td>0.002913747</td><td>0.03917922</td><td>0.95790704</td></tr>\n",
       "\t<tr><th scope=row>125</th><td>0.004446189</td><td>0.06597727</td><td>0.92957654</td></tr>\n",
       "\t<tr><th scope=row>127</th><td>0.012700857</td><td>0.27913915</td><td>0.70815999</td></tr>\n",
       "\t<tr><th scope=row>129</th><td>0.003238216</td><td>0.04325749</td><td>0.95350429</td></tr>\n",
       "\t<tr><th scope=row>131</th><td>0.003937094</td><td>0.05862203</td><td>0.93744088</td></tr>\n",
       "\t<tr><th scope=row>133</th><td>0.003100011</td><td>0.04081233</td><td>0.95608766</td></tr>\n",
       "\t<tr><th scope=row>135</th><td>0.004451327</td><td>0.06782558</td><td>0.92772309</td></tr>\n",
       "\t<tr><th scope=row>137</th><td>0.003325120</td><td>0.04362663</td><td>0.95304825</td></tr>\n",
       "\t<tr><th scope=row>139</th><td>0.013170111</td><td>0.28506791</td><td>0.70176198</td></tr>\n",
       "\t<tr><th scope=row>141</th><td>0.003369314</td><td>0.04510965</td><td>0.95152103</td></tr>\n",
       "\t<tr><th scope=row>143</th><td>0.003993739</td><td>0.05519673</td><td>0.94080953</td></tr>\n",
       "\t<tr><th scope=row>145</th><td>0.003249660</td><td>0.04292042</td><td>0.95382992</td></tr>\n",
       "\t<tr><th scope=row>147</th><td>0.005448537</td><td>0.08547869</td><td>0.90907278</td></tr>\n",
       "\t<tr><th scope=row>149</th><td>0.003954496</td><td>0.05383581</td><td>0.94220970</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 75 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & setosa & versicolor & virginica\\\\\n",
       "\\hline\n",
       "\t1 & 0.97909070 & 0.01990905 & 0.0010002462\\\\\n",
       "\t3 & 0.97650269 & 0.02238917 & 0.0011081386\\\\\n",
       "\t5 & 0.97957425 & 0.01944512 & 0.0009806315\\\\\n",
       "\t7 & 0.97564607 & 0.02321161 & 0.0011423237\\\\\n",
       "\t9 & 0.96647924 & 0.03202518 & 0.0014955750\\\\\n",
       "\t11 & 0.98009040 & 0.01895226 & 0.0009573385\\\\\n",
       "\t13 & 0.97296328 & 0.02579134 & 0.0012453770\\\\\n",
       "\t15 & 0.98374886 & 0.01544954 & 0.0008015995\\\\\n",
       "\t17 & 0.98210521 & 0.01702091 & 0.0008738800\\\\\n",
       "\t19 & 0.97862301 & 0.02036198 & 0.0010150123\\\\\n",
       "\t21 & 0.97361171 & 0.02517580 & 0.0012124954\\\\\n",
       "\t23 & 0.98231725 & 0.01681571 & 0.0008670413\\\\\n",
       "\t25 & 0.96052423 & 0.03778454 & 0.0016912305\\\\\n",
       "\t27 & 0.97167077 & 0.02703694 & 0.0012922870\\\\\n",
       "\t29 & 0.97856430 & 0.02041426 & 0.0010214362\\\\\n",
       "\t31 & 0.96667067 & 0.03184997 & 0.0014793581\\\\\n",
       "\t33 & 0.98214845 & 0.01698049 & 0.0008710631\\\\\n",
       "\t35 & 0.97116502 & 0.02752235 & 0.0013126356\\\\\n",
       "\t37 & 0.98107477 & 0.01800806 & 0.0009171654\\\\\n",
       "\t39 & 0.97219957 & 0.02652021 & 0.0012802259\\\\\n",
       "\t41 & 0.97953851 & 0.01947836 & 0.0009831349\\\\\n",
       "\t43 & 0.97521951 & 0.02361926 & 0.0011612267\\\\\n",
       "\t45 & 0.97043161 & 0.02823553 & 0.0013328648\\\\\n",
       "\t47 & 0.97883376 & 0.02015707 & 0.0010091689\\\\\n",
       "\t49 & 0.97985446 & 0.01917815 & 0.0009673904\\\\\n",
       "\t51 & 0.01553383 & 0.96126489 & 0.0232012872\\\\\n",
       "\t53 & 0.01607439 & 0.92726892 & 0.0566566899\\\\\n",
       "\t55 & 0.01810790 & 0.89310649 & 0.0887856130\\\\\n",
       "\t57 & 0.01937892 & 0.89090739 & 0.0897136898\\\\\n",
       "\t59 & 0.01578612 & 0.94965555 & 0.0345583345\\\\\n",
       "\t⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t91 & 0.020818416 & 0.77531236 & 0.20386923\\\\\n",
       "\t93 & 0.019386628 & 0.94739809 & 0.03321528\\\\\n",
       "\t95 & 0.020764847 & 0.88841335 & 0.09082180\\\\\n",
       "\t97 & 0.020076931 & 0.92997039 & 0.04995268\\\\\n",
       "\t99 & 0.059335976 & 0.92328504 & 0.01737899\\\\\n",
       "\t101 & 0.002785882 & 0.03577229 & 0.96144183\\\\\n",
       "\t103 & 0.003768930 & 0.05405064 & 0.94218043\\\\\n",
       "\t105 & 0.003079249 & 0.04064080 & 0.95627995\\\\\n",
       "\t107 & 0.004807830 & 0.06565437 & 0.92953780\\\\\n",
       "\t109 & 0.003365508 & 0.04663381 & 0.95000068\\\\\n",
       "\t111 & 0.011017522 & 0.22739646 & 0.76158601\\\\\n",
       "\t113 & 0.004810508 & 0.07360760 & 0.92158189\\\\\n",
       "\t115 & 0.003107860 & 0.03948636 & 0.95740578\\\\\n",
       "\t117 & 0.005803757 & 0.09603333 & 0.89816291\\\\\n",
       "\t119 & 0.002646899 & 0.03455211 & 0.96280099\\\\\n",
       "\t121 & 0.003821692 & 0.05378072 & 0.94239759\\\\\n",
       "\t123 & 0.002913747 & 0.03917922 & 0.95790704\\\\\n",
       "\t125 & 0.004446189 & 0.06597727 & 0.92957654\\\\\n",
       "\t127 & 0.012700857 & 0.27913915 & 0.70815999\\\\\n",
       "\t129 & 0.003238216 & 0.04325749 & 0.95350429\\\\\n",
       "\t131 & 0.003937094 & 0.05862203 & 0.93744088\\\\\n",
       "\t133 & 0.003100011 & 0.04081233 & 0.95608766\\\\\n",
       "\t135 & 0.004451327 & 0.06782558 & 0.92772309\\\\\n",
       "\t137 & 0.003325120 & 0.04362663 & 0.95304825\\\\\n",
       "\t139 & 0.013170111 & 0.28506791 & 0.70176198\\\\\n",
       "\t141 & 0.003369314 & 0.04510965 & 0.95152103\\\\\n",
       "\t143 & 0.003993739 & 0.05519673 & 0.94080953\\\\\n",
       "\t145 & 0.003249660 & 0.04292042 & 0.95382992\\\\\n",
       "\t147 & 0.005448537 & 0.08547869 & 0.90907278\\\\\n",
       "\t149 & 0.003954496 & 0.05383581 & 0.94220970\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 75 × 3 of type dbl\n",
       "\n",
       "| <!--/--> | setosa | versicolor | virginica |\n",
       "|---|---|---|---|\n",
       "| 1 | 0.97909070 | 0.01990905 | 0.0010002462 |\n",
       "| 3 | 0.97650269 | 0.02238917 | 0.0011081386 |\n",
       "| 5 | 0.97957425 | 0.01944512 | 0.0009806315 |\n",
       "| 7 | 0.97564607 | 0.02321161 | 0.0011423237 |\n",
       "| 9 | 0.96647924 | 0.03202518 | 0.0014955750 |\n",
       "| 11 | 0.98009040 | 0.01895226 | 0.0009573385 |\n",
       "| 13 | 0.97296328 | 0.02579134 | 0.0012453770 |\n",
       "| 15 | 0.98374886 | 0.01544954 | 0.0008015995 |\n",
       "| 17 | 0.98210521 | 0.01702091 | 0.0008738800 |\n",
       "| 19 | 0.97862301 | 0.02036198 | 0.0010150123 |\n",
       "| 21 | 0.97361171 | 0.02517580 | 0.0012124954 |\n",
       "| 23 | 0.98231725 | 0.01681571 | 0.0008670413 |\n",
       "| 25 | 0.96052423 | 0.03778454 | 0.0016912305 |\n",
       "| 27 | 0.97167077 | 0.02703694 | 0.0012922870 |\n",
       "| 29 | 0.97856430 | 0.02041426 | 0.0010214362 |\n",
       "| 31 | 0.96667067 | 0.03184997 | 0.0014793581 |\n",
       "| 33 | 0.98214845 | 0.01698049 | 0.0008710631 |\n",
       "| 35 | 0.97116502 | 0.02752235 | 0.0013126356 |\n",
       "| 37 | 0.98107477 | 0.01800806 | 0.0009171654 |\n",
       "| 39 | 0.97219957 | 0.02652021 | 0.0012802259 |\n",
       "| 41 | 0.97953851 | 0.01947836 | 0.0009831349 |\n",
       "| 43 | 0.97521951 | 0.02361926 | 0.0011612267 |\n",
       "| 45 | 0.97043161 | 0.02823553 | 0.0013328648 |\n",
       "| 47 | 0.97883376 | 0.02015707 | 0.0010091689 |\n",
       "| 49 | 0.97985446 | 0.01917815 | 0.0009673904 |\n",
       "| 51 | 0.01553383 | 0.96126489 | 0.0232012872 |\n",
       "| 53 | 0.01607439 | 0.92726892 | 0.0566566899 |\n",
       "| 55 | 0.01810790 | 0.89310649 | 0.0887856130 |\n",
       "| 57 | 0.01937892 | 0.89090739 | 0.0897136898 |\n",
       "| 59 | 0.01578612 | 0.94965555 | 0.0345583345 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 91 | 0.020818416 | 0.77531236 | 0.20386923 |\n",
       "| 93 | 0.019386628 | 0.94739809 | 0.03321528 |\n",
       "| 95 | 0.020764847 | 0.88841335 | 0.09082180 |\n",
       "| 97 | 0.020076931 | 0.92997039 | 0.04995268 |\n",
       "| 99 | 0.059335976 | 0.92328504 | 0.01737899 |\n",
       "| 101 | 0.002785882 | 0.03577229 | 0.96144183 |\n",
       "| 103 | 0.003768930 | 0.05405064 | 0.94218043 |\n",
       "| 105 | 0.003079249 | 0.04064080 | 0.95627995 |\n",
       "| 107 | 0.004807830 | 0.06565437 | 0.92953780 |\n",
       "| 109 | 0.003365508 | 0.04663381 | 0.95000068 |\n",
       "| 111 | 0.011017522 | 0.22739646 | 0.76158601 |\n",
       "| 113 | 0.004810508 | 0.07360760 | 0.92158189 |\n",
       "| 115 | 0.003107860 | 0.03948636 | 0.95740578 |\n",
       "| 117 | 0.005803757 | 0.09603333 | 0.89816291 |\n",
       "| 119 | 0.002646899 | 0.03455211 | 0.96280099 |\n",
       "| 121 | 0.003821692 | 0.05378072 | 0.94239759 |\n",
       "| 123 | 0.002913747 | 0.03917922 | 0.95790704 |\n",
       "| 125 | 0.004446189 | 0.06597727 | 0.92957654 |\n",
       "| 127 | 0.012700857 | 0.27913915 | 0.70815999 |\n",
       "| 129 | 0.003238216 | 0.04325749 | 0.95350429 |\n",
       "| 131 | 0.003937094 | 0.05862203 | 0.93744088 |\n",
       "| 133 | 0.003100011 | 0.04081233 | 0.95608766 |\n",
       "| 135 | 0.004451327 | 0.06782558 | 0.92772309 |\n",
       "| 137 | 0.003325120 | 0.04362663 | 0.95304825 |\n",
       "| 139 | 0.013170111 | 0.28506791 | 0.70176198 |\n",
       "| 141 | 0.003369314 | 0.04510965 | 0.95152103 |\n",
       "| 143 | 0.003993739 | 0.05519673 | 0.94080953 |\n",
       "| 145 | 0.003249660 | 0.04292042 | 0.95382992 |\n",
       "| 147 | 0.005448537 | 0.08547869 | 0.90907278 |\n",
       "| 149 | 0.003954496 | 0.05383581 | 0.94220970 |\n",
       "\n"
      ],
      "text/plain": [
       "    setosa      versicolor virginica   \n",
       "1   0.97909070  0.01990905 0.0010002462\n",
       "3   0.97650269  0.02238917 0.0011081386\n",
       "5   0.97957425  0.01944512 0.0009806315\n",
       "7   0.97564607  0.02321161 0.0011423237\n",
       "9   0.96647924  0.03202518 0.0014955750\n",
       "11  0.98009040  0.01895226 0.0009573385\n",
       "13  0.97296328  0.02579134 0.0012453770\n",
       "15  0.98374886  0.01544954 0.0008015995\n",
       "17  0.98210521  0.01702091 0.0008738800\n",
       "19  0.97862301  0.02036198 0.0010150123\n",
       "21  0.97361171  0.02517580 0.0012124954\n",
       "23  0.98231725  0.01681571 0.0008670413\n",
       "25  0.96052423  0.03778454 0.0016912305\n",
       "27  0.97167077  0.02703694 0.0012922870\n",
       "29  0.97856430  0.02041426 0.0010214362\n",
       "31  0.96667067  0.03184997 0.0014793581\n",
       "33  0.98214845  0.01698049 0.0008710631\n",
       "35  0.97116502  0.02752235 0.0013126356\n",
       "37  0.98107477  0.01800806 0.0009171654\n",
       "39  0.97219957  0.02652021 0.0012802259\n",
       "41  0.97953851  0.01947836 0.0009831349\n",
       "43  0.97521951  0.02361926 0.0011612267\n",
       "45  0.97043161  0.02823553 0.0013328648\n",
       "47  0.97883376  0.02015707 0.0010091689\n",
       "49  0.97985446  0.01917815 0.0009673904\n",
       "51  0.01553383  0.96126489 0.0232012872\n",
       "53  0.01607439  0.92726892 0.0566566899\n",
       "55  0.01810790  0.89310649 0.0887856130\n",
       "57  0.01937892  0.89090739 0.0897136898\n",
       "59  0.01578612  0.94965555 0.0345583345\n",
       "⋮   ⋮           ⋮          ⋮           \n",
       "91  0.020818416 0.77531236 0.20386923  \n",
       "93  0.019386628 0.94739809 0.03321528  \n",
       "95  0.020764847 0.88841335 0.09082180  \n",
       "97  0.020076931 0.92997039 0.04995268  \n",
       "99  0.059335976 0.92328504 0.01737899  \n",
       "101 0.002785882 0.03577229 0.96144183  \n",
       "103 0.003768930 0.05405064 0.94218043  \n",
       "105 0.003079249 0.04064080 0.95627995  \n",
       "107 0.004807830 0.06565437 0.92953780  \n",
       "109 0.003365508 0.04663381 0.95000068  \n",
       "111 0.011017522 0.22739646 0.76158601  \n",
       "113 0.004810508 0.07360760 0.92158189  \n",
       "115 0.003107860 0.03948636 0.95740578  \n",
       "117 0.005803757 0.09603333 0.89816291  \n",
       "119 0.002646899 0.03455211 0.96280099  \n",
       "121 0.003821692 0.05378072 0.94239759  \n",
       "123 0.002913747 0.03917922 0.95790704  \n",
       "125 0.004446189 0.06597727 0.92957654  \n",
       "127 0.012700857 0.27913915 0.70815999  \n",
       "129 0.003238216 0.04325749 0.95350429  \n",
       "131 0.003937094 0.05862203 0.93744088  \n",
       "133 0.003100011 0.04081233 0.95608766  \n",
       "135 0.004451327 0.06782558 0.92772309  \n",
       "137 0.003325120 0.04362663 0.95304825  \n",
       "139 0.013170111 0.28506791 0.70176198  \n",
       "141 0.003369314 0.04510965 0.95152103  \n",
       "143 0.003993739 0.05519673 0.94080953  \n",
       "145 0.003249660 0.04292042 0.95382992  \n",
       "147 0.005448537 0.08547869 0.90907278  \n",
       "149 0.003954496 0.05383581 0.94220970  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(iris.nnet, iris.test, type=\"raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'setosa'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'virginica'</li><li>'virginica'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'versicolor'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li><li>'virginica'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'setosa'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'versicolor'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\item 'virginica'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'setosa'\n",
       "2. 'setosa'\n",
       "3. 'setosa'\n",
       "4. 'setosa'\n",
       "5. 'setosa'\n",
       "6. 'setosa'\n",
       "7. 'setosa'\n",
       "8. 'setosa'\n",
       "9. 'setosa'\n",
       "10. 'setosa'\n",
       "11. 'setosa'\n",
       "12. 'setosa'\n",
       "13. 'setosa'\n",
       "14. 'setosa'\n",
       "15. 'setosa'\n",
       "16. 'setosa'\n",
       "17. 'setosa'\n",
       "18. 'setosa'\n",
       "19. 'setosa'\n",
       "20. 'setosa'\n",
       "21. 'setosa'\n",
       "22. 'setosa'\n",
       "23. 'setosa'\n",
       "24. 'setosa'\n",
       "25. 'setosa'\n",
       "26. 'versicolor'\n",
       "27. 'versicolor'\n",
       "28. 'versicolor'\n",
       "29. 'versicolor'\n",
       "30. 'versicolor'\n",
       "31. 'versicolor'\n",
       "32. 'versicolor'\n",
       "33. 'versicolor'\n",
       "34. 'versicolor'\n",
       "35. 'versicolor'\n",
       "36. 'virginica'\n",
       "37. 'virginica'\n",
       "38. 'versicolor'\n",
       "39. 'versicolor'\n",
       "40. 'versicolor'\n",
       "41. 'versicolor'\n",
       "42. 'versicolor'\n",
       "43. 'versicolor'\n",
       "44. 'versicolor'\n",
       "45. 'versicolor'\n",
       "46. 'versicolor'\n",
       "47. 'versicolor'\n",
       "48. 'versicolor'\n",
       "49. 'versicolor'\n",
       "50. 'versicolor'\n",
       "51. 'virginica'\n",
       "52. 'virginica'\n",
       "53. 'virginica'\n",
       "54. 'virginica'\n",
       "55. 'virginica'\n",
       "56. 'virginica'\n",
       "57. 'virginica'\n",
       "58. 'virginica'\n",
       "59. 'virginica'\n",
       "60. 'virginica'\n",
       "61. 'virginica'\n",
       "62. 'virginica'\n",
       "63. 'virginica'\n",
       "64. 'virginica'\n",
       "65. 'virginica'\n",
       "66. 'virginica'\n",
       "67. 'virginica'\n",
       "68. 'virginica'\n",
       "69. 'virginica'\n",
       "70. 'virginica'\n",
       "71. 'virginica'\n",
       "72. 'virginica'\n",
       "73. 'virginica'\n",
       "74. 'virginica'\n",
       "75. 'virginica'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n",
       " [6] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n",
       "[11] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n",
       "[16] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n",
       "[21] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n",
       "[26] \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n",
       "[31] \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n",
       "[36] \"virginica\"  \"virginica\"  \"versicolor\" \"versicolor\" \"versicolor\"\n",
       "[41] \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n",
       "[46] \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n",
       "[51] \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n",
       "[56] \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n",
       "[61] \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n",
       "[66] \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n",
       "[71] \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(iris.nnet, iris.test, type=\"class\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深層学習もやってみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 依存対象 (dependency) ‘RCurl’ もインストールします \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/4x/vf52k2q52wx0sqrm0t5hfr040000gn/T//RtmpOD8YxV/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"h2o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Your next step is to start H2O:\n",
      "    > h2o.init()\n",
      "\n",
      "For H2O package documentation, ask for help:\n",
      "    > ??h2o\n",
      "\n",
      "After starting H2O, you can use the Web UI at http://localhost:54321\n",
      "For more information visit https://docs.h2o.ai\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      " 次のパッケージを付け加えます: ‘h2o’ \n",
      "\n",
      "\n",
      " 以下のオブジェクトは ‘package:stats’ からマスクされています: \n",
      "\n",
      "     cor, sd, var \n",
      "\n",
      "\n",
      " 以下のオブジェクトは ‘package:base’ からマスクされています: \n",
      "\n",
      "     %*%, %in%, &&, apply, as.factor, as.numeric, colnames, colnames<-,\n",
      "    ifelse, is.character, is.factor, is.numeric, log, log10, log1p,\n",
      "    log2, round, signif, trunc, || \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(h2o)\n",
    "library(kernlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### いざ実践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         18 seconds 15 milliseconds \n",
      "    H2O cluster timezone:       Asia/Tokyo \n",
      "    H2O data parsing timezone:  UTC \n",
      "    H2O cluster version:        3.38.0.1 \n",
      "    H2O cluster version age:    1 month and 21 days  \n",
      "    H2O cluster name:           H2O_started_from_R_OgawaAyumu_skv589 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   2.00 GB \n",
      "    H2O cluster total cores:    8 \n",
      "    H2O cluster allowed cores:  8 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    H2O Internal Security:      FALSE \n",
      "    R Version:                  R version 4.1.3 (2022-03-10) \n",
      "\n",
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "h2o.init()\n",
    "spam.hex = as.h2o(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "tr = h2o.deeplearning(x=1:57, y=58, training_frame=spam.hex, hidden=c(30,20,10), epochs=100, nfolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Details:\n",
       "==============\n",
       "\n",
       "H2OBinomialModel: deeplearning\n",
       "Model ID:  DeepLearning_model_R_1667978543529_1 \n",
       "Status of Neuron Layers: predicting type, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,592 weights/biases, 41.4 KB, 506,110 training samples, mini-batch size 1\n",
       "  layer units      type dropout       l1       l2 mean_rate rate_rms momentum\n",
       "1     1    57     Input  0.00 %       NA       NA        NA       NA       NA\n",
       "2     2    30 Rectifier  0.00 % 0.000000 0.000000  1.004199 0.000299 0.000000\n",
       "3     3    20 Rectifier  0.00 % 0.000000 0.000000  0.818128 0.352692 0.000000\n",
       "4     4    10 Rectifier  0.00 % 0.000000 0.000000  0.946961 0.209715 0.000000\n",
       "5     5     2   Softmax      NA 0.000000 0.000000  1.004153 0.000229 0.000000\n",
       "  mean_weight weight_rms mean_bias bias_rms\n",
       "1          NA         NA        NA       NA\n",
       "2    0.018214   0.245087  0.468191 0.106731\n",
       "3   -0.015312   0.240653  0.995003 0.101695\n",
       "4    0.048145   0.372435  1.020548 0.065025\n",
       "5   -0.374844   1.989696 -0.025187 0.170138\n",
       "\n",
       "\n",
       "H2OBinomialMetrics: deeplearning\n",
       "** Reported on training data. **\n",
       "** Metrics reported on full training frame **\n",
       "\n",
       "MSE:  0.1424511\n",
       "RMSE:  0.377427\n",
       "LogLoss:  1.057263\n",
       "Mean Per-Class Error:  0.03976897\n",
       "AUC:  0.9612877\n",
       "AUCPR:  0.9685981\n",
       "Gini:  0.9225754\n",
       "\n",
       "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
       "        nonspam spam    Error       Rate\n",
       "nonspam    2780    8 0.002869    =8/2788\n",
       "spam        139 1674 0.076669  =139/1813\n",
       "Totals     2919 1682 0.031950  =147/4601\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "                        metric threshold       value idx\n",
       "1                       max f1  0.000060    0.957940 398\n",
       "2                       max f2  0.000060    0.936870 398\n",
       "3                 max f0point5  0.000060    0.979979 398\n",
       "4                 max accuracy  0.000060    0.968050 398\n",
       "5                max precision  0.999992    1.000000   0\n",
       "6                   max recall  0.000000    1.000000 399\n",
       "7              max specificity  0.999992    1.000000   0\n",
       "8             max absolute_mcc  0.000060    0.933945 398\n",
       "9   max min_per_class_accuracy  0.000060    0.923331 398\n",
       "10 max mean_per_class_accuracy  0.000060    0.960231 398\n",
       "11                     max tns  0.999992 2788.000000   0\n",
       "12                     max fns  0.999992 1292.000000   0\n",
       "13                     max fps  0.000000 2788.000000 399\n",
       "14                     max tps  0.000000 1813.000000 399\n",
       "15                     max tnr  0.999992    1.000000   0\n",
       "16                     max fnr  0.999992    0.712631   0\n",
       "17                     max fpr  0.000000    1.000000 399\n",
       "18                     max tpr  0.000000    1.000000 399\n",
       "\n",
       "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
       "\n",
       "H2OBinomialMetrics: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "** 3-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n",
       "\n",
       "MSE:  0.08755245\n",
       "RMSE:  0.2958926\n",
       "LogLoss:  0.4481429\n",
       "Mean Per-Class Error:  0.08222874\n",
       "AUC:  0.962861\n",
       "AUCPR:  0.933\n",
       "Gini:  0.925722\n",
       "\n",
       "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
       "        nonspam spam    Error       Rate\n",
       "nonspam    2574  214 0.076758  =214/2788\n",
       "spam        159 1654 0.087700  =159/1813\n",
       "Totals     2733 1868 0.081069  =373/4601\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "                        metric threshold       value idx\n",
       "1                       max f1  0.069889    0.898669 334\n",
       "2                       max f2  0.007320    0.928587 380\n",
       "3                 max f0point5  0.323386    0.898943 246\n",
       "4                 max accuracy  0.069889    0.918931 334\n",
       "5                max precision  0.998814    0.963840   4\n",
       "6                   max recall  0.000005    1.000000 399\n",
       "7              max specificity  0.999988    0.991750   0\n",
       "8             max absolute_mcc  0.069889    0.831392 334\n",
       "9   max min_per_class_accuracy  0.058750    0.916713 341\n",
       "10 max mean_per_class_accuracy  0.021635    0.918772 365\n",
       "11                     max tns  0.999988 2765.000000   0\n",
       "12                     max fns  0.999988 1202.000000   0\n",
       "13                     max fps  0.000005 2788.000000 399\n",
       "14                     max tps  0.000005 1813.000000 399\n",
       "15                     max tnr  0.999988    0.991750   0\n",
       "16                     max fnr  0.999988    0.662990   0\n",
       "17                     max fpr  0.000005    1.000000 399\n",
       "18                     max tpr  0.000005    1.000000 399\n",
       "\n",
       "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
       "Cross-Validation Metrics Summary: \n",
       "                              mean       sd cv_1_valid cv_2_valid cv_3_valid\n",
       "accuracy                  0.931599 0.004936   0.936793   0.931034   0.926970\n",
       "auc                       0.973027 0.002129   0.971640   0.971963   0.975479\n",
       "err                       0.068401 0.004936   0.063207   0.068966   0.073030\n",
       "err_count               105.000000 9.539392  95.000000 106.000000 114.000000\n",
       "f0point5                  0.913638 0.005627   0.918789   0.914493   0.907633\n",
       "f1                        0.913169 0.004922   0.918315   0.912685   0.908507\n",
       "f2                        0.912703 0.004513   0.917841   0.910885   0.909383\n",
       "lift_top_group            2.538643 0.038614   2.582474   2.523809   2.509646\n",
       "logloss                   0.448028 0.042601   0.418658   0.496887   0.428537\n",
       "max_per_class_error       0.087606 0.004447   0.082474   0.090312   0.090032\n",
       "mcc                       0.856741 0.009555   0.866769   0.855710   0.847743\n",
       "mean_per_class_accuracy   0.928238 0.004635   0.933247   0.927366   0.924100\n",
       "mean_per_class_error      0.071762 0.004635   0.066753   0.072634   0.075900\n",
       "mse                       0.087452 0.036185   0.062334   0.128928   0.071095\n",
       "pr_auc                    0.957890 0.006179   0.954015   0.965015   0.954638\n",
       "precision                 0.913953 0.006214   0.919105   0.915702   0.907051\n",
       "r2                        0.633921 0.150646   0.737300   0.461075   0.703388\n",
       "recall                    0.912394 0.004447   0.917526   0.909688   0.909968\n",
       "rmse                      0.291790 0.058877   0.249668   0.359065   0.266637\n",
       "specificity               0.944081 0.005432   0.948968   0.945043   0.938232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
